# Image-Super-Resolution
An adversarial algorithm for generating super resolution (SR) of images.

## Problem Description
When a high resolution image is resized (perhaps because of space restrictions), some information is invariably lost. This results the image to look blurry. There are many algorithms designed to recover the lost information. Even though not every pixel can be restored, these algorithms seeks a very good approximation of the original high resolution image by "filling in the gaps" in some way and this process is called super-resolution.

This project is a pytorch reproduction of the adversarial algorithm called SRGAN: https://arxiv.org/pdf/1609.04802.pdf by Christian Ledig et al.

## Algorithm description
The algorithm works in two stages:

1) An network G with a Resnet architecture takes in low-resolution (LR) images with size w x h and outputs images of size 4w x 4h. Is is then trained against the high-resolution (HR) training images (also with sie 4w x 4h) with pixel-wise **mean-squared error** (MSE) loss. The model at this stage is called **SRResnet**.
2) The SRResnet model G is taken as the **generator** in an adversarial model, which also has a **discriminator** network D. Then these two networks play the usual 2-player minimax game 
<img width="493" alt="eq1" src="https://user-images.githubusercontent.com/24876548/134604418-721ca78f-6c68-4972-9f35-f131a5762a0e.png">
where the generator Gtries to generate images convicing enough to "fool" the discriminator D, and D tries to maximize correct identifications of real images from "fake" images generated by G. 

The second term of the equation serves as the **adversarial loss** for G, but due to gradient vanishing reasons, we minimize -log(D(G(z))) instead. This loss is denoted by g_gan_loss in the code. The **MSE loss** used in stage 1) with SRResnet is also used here to train pixel similarity with the real HR images, in the code this is denoted by mse_loss.

In addition, Christian Ledig et al. introduce a **perceptual loss**. The authors found that methods using solely MSE loss for pixel similarity resulted in generated images that are too smooth to be photorealistic. This would suggest that this method somehow misses the "bigger picture" by trying to maximize per-pixel similarity. Therefore the authors suggest that trying to train for **feature similarity** is also an important component of the model. This is done by feeding forward the generated and real images into a pretrained VGG19 model and comparing the features in an intermediate layer (this is taken to be the activation layer just before the 4th maxpool layer). In the code this is denoted by vgg_loss.

Finally the loss being trained by G is mse_loss + 0.006 * vgg_loss + 0.001 * g_gan_loss. The coefficients are there to scale the three losses to a similar range so that none of them dominant the training process. 

This model is named **SRGAN** (VGG_54).

## Dataset
I trained the SRGAN model on the [DIV2K dataset](https://data.vision.ee.ethz.ch/cvl/DIV2K/). This dataset was used in the competitions CVPR 2017 and CVPR 2018. It contains 800 HR images for trianing and 100 HR/LR images for validation. 

## Training Parameters
I trained the model on Google Colab, which has a GPU storage limit of 15GB. Therefore I used the batch size 2 for both stages of training. Then I followed the paper's training specifications:
* 1e-4 learning rate for training SRResnet.
* 1e-4 learning rate for the first 10^5 iterations (250 epochs in our case) and 1e-5 learning rate for the remaining 10^5 iterations (250 epochs) for training SRGAN.
* LR images are scaled to [0, 1] whereas HR images are scaled to [-1, 1]. 
* The optimizer used is Adam

## Results
I've included several examples of super-resolution below, comparing the models SRResnet and SRGAN with the real HR image.


